---
title: "Predicting Quality of Weight-Lifting Form"
output: html_document
---
**BACKGROUND.** Using the *Weight Lifting Exercises Dataset* (courteously provided by Groupware@LES, http://groupware.les.inf.pic-rio.br/har), the objective was to predict proper vs. improper weight-lifting form based on multiple readings from sensors attached to the upper arm, forearm, and belt of the weight lifter as well as to the dumbbell itself. Specifically, the goal was to classify the movements as either (A) correct form or one of four types of bad form: (B) throwing elbows to the front, (C) lifting dumbbell only halfway, (D) lowering dumbbell only halfway, or (E) throwing hips to the front.

**DATA SOURCE.** The training data, consisting of 19622 observations, were downloaded from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv. An additional test set of 20 observations was downloaded from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv.

**PACKAGES USED.** The data.table structure (instead of the base dataframe structure) was used to speed up data handling. The caret library was used for data partitioning, training a random forest, and validating its predictions.

```{r}
library(caret); library(data.table)
```

**DATA CLEANING.** Data were read from the pml-training.csv file, omitting columns with missing values and unique identifiers associated with the observations, such as the name of the weight lifter and the timestamp for the observation. The variable 'classe', which indicates the category of movement ('A':'E', as described in **BACKGROUND**) to be predicted, was converted to a factor variable with five levels.

```{r}
data = fread('pml-training.csv',select=c(8:11,37:49,60:68,84:86,102,113:124,140,151:160))
data$classe = as.factor(data$classe)
```

**MODEL FEATURES.** The remaining features, corresponding to various sensor readings, were considered to be candidate predictors of the movement class:
```{r}
names(data)[1:52]
```

**DATA PARTITIONING**. The data set was randomly partitioned into a 75%/25% split for model training and validation, respectively.

```{r}
set.seed(42)
inTrain = createDataPartition(y=data$classe, p=0.75, list=F)
training = data[row.names(data)%in%inTrain]
validation = data[!row.names(data)%in%inTrain]
```

**MACHINE LEARNING ALGORITHM.** A random forest algorithm was used to optimize the prediction of weight-lifting form, drawing from all of the candidate features listed under **MODEL FEATURES**.

```{r}
set.seed(42)
rf_model = train(classe ~ ., method='rf',data=training)
```

**EXPECTED OUT OF SAMPLE ERROR**
The internal estimate of the out-of-bag (OOB) error generated by the random forest algorithm was exceptionally low (less than 1%):

```{r}
rf_model$finalModel
```

Although the OOB estimate has proven to be unbiased in many tests, additional cross-validation of the model was performed by predicting the 25% of cases withheld from the training set. These predictions proved to be exceptionally accurate (99.5% overall, with sensitivities ranging from 98.5-100% and specificities ranging from 99.7-100%), as indicated by the confusion matrix and cross-validation statistics printed out below:

```{r}
validate_predict = predict(rf_model,validation)
confusionMatrix(validate_predict,validation$classe)
```

Finally, the model was applied to the 20-observation test set, which withheld the correct classifications until the predictions were submitted for automatic grading on the Coursera website. Accuracy of these predictions was 100%.
